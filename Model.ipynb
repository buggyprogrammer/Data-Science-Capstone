{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e4f7b46-35fb-4590-a354-0733657de9d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T17:35:44.022930Z",
     "iopub.status.busy": "2021-10-17T17:35:44.022930Z",
     "iopub.status.idle": "2021-10-17T17:35:46.876465Z",
     "shell.execute_reply": "2021-10-17T17:35:46.875468Z",
     "shell.execute_reply.started": "2021-10-17T17:35:44.022930Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aae4d88e-cb0e-4384-89b3-3408aa73c978",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T19:27:29.280587Z",
     "iopub.status.busy": "2021-10-17T19:27:29.280587Z",
     "iopub.status.idle": "2021-10-17T19:27:29.318484Z",
     "shell.execute_reply": "2021-10-17T19:27:29.317490Z",
     "shell.execute_reply.started": "2021-10-17T19:27:29.280587Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.813399</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.696814</td>\n",
       "      <td>0.183531</td>\n",
       "      <td>0.260117</td>\n",
       "      <td>0.821764</td>\n",
       "      <td>1.364180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.833906</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.036596</td>\n",
       "      <td>0.183531</td>\n",
       "      <td>-0.843284</td>\n",
       "      <td>-0.168409</td>\n",
       "      <td>0.126452</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.188996</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.054048</td>\n",
       "      <td>0.183531</td>\n",
       "      <td>-1.457745</td>\n",
       "      <td>0.935284</td>\n",
       "      <td>0.230161</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.833906</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-0.674132</td>\n",
       "      <td>-0.791683</td>\n",
       "      <td>-0.586404</td>\n",
       "      <td>-1.298725</td>\n",
       "      <td>-1.480075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.603317</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.696814</td>\n",
       "      <td>0.343910</td>\n",
       "      <td>1.462682</td>\n",
       "      <td>2.336680</td>\n",
       "      <td>0.327328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
       "0     0.813399    148.0           72.0       0.696814  0.183531  0.260117   \n",
       "1    -0.833906     85.0           66.0       0.036596  0.183531 -0.843284   \n",
       "2     1.188996    183.0           64.0       0.054048  0.183531 -1.457745   \n",
       "3    -0.833906     89.0           66.0      -0.674132 -0.791683 -0.586404   \n",
       "4    -1.603317    137.0           40.0       0.696814  0.343910  1.462682   \n",
       "\n",
       "   DiabetesPedigreeFunction       Age  Outcome  \n",
       "0                  0.821764  1.364180        1  \n",
       "1                 -0.168409  0.126452        0  \n",
       "2                  0.935284  0.230161        1  \n",
       "3                 -1.298725 -1.480075        0  \n",
       "4                  2.336680  0.327328        1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/Preprocessed.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ed278e20-5bbc-43b4-af2e-3e0885437576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T19:27:29.556162Z",
     "iopub.status.busy": "2021-10-17T19:27:29.555124Z",
     "iopub.status.idle": "2021-10-17T19:27:29.582051Z",
     "shell.execute_reply": "2021-10-17T19:27:29.580058Z",
     "shell.execute_reply.started": "2021-10-17T19:27:29.556162Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8) (768,)\n"
     ]
    }
   ],
   "source": [
    "features = df.drop('Outcome', axis=1)\n",
    "label = df['Outcome']\n",
    "print(features.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4abfaba0-89b0-4e5e-b88f-ec61e0308f83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T19:55:09.410398Z",
     "iopub.status.busy": "2021-10-17T19:55:09.409400Z",
     "iopub.status.idle": "2021-10-17T19:55:09.427352Z",
     "shell.execute_reply": "2021-10-17T19:55:09.426396Z",
     "shell.execute_reply.started": "2021-10-17T19:55:09.410398Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "19dc90d7-eb09-4995-b52f-05909271aaf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T04:46:34.775377Z",
     "iopub.status.busy": "2021-10-18T04:46:34.774378Z",
     "iopub.status.idle": "2021-10-18T04:46:35.042661Z",
     "shell.execute_reply": "2021-10-18T04:46:35.040665Z",
     "shell.execute_reply.started": "2021-10-18T04:46:34.775377Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] KNN Model Performance...\n",
      "\n",
      "[INFO] Performance on 0 fold\n",
      "0.6688311688311688\n",
      "[[77 23]\n",
      " [28 26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       100\n",
      "           1       0.53      0.48      0.50        54\n",
      "\n",
      "    accuracy                           0.67       154\n",
      "   macro avg       0.63      0.63      0.63       154\n",
      "weighted avg       0.66      0.67      0.66       154\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "[INFO] Performance on 1 fold\n",
      "0.6493506493506493\n",
      "[[70 30]\n",
      " [24 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72       100\n",
      "           1       0.50      0.56      0.53        54\n",
      "\n",
      "    accuracy                           0.65       154\n",
      "   macro avg       0.62      0.63      0.62       154\n",
      "weighted avg       0.66      0.65      0.65       154\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "[INFO] Performance on 2 fold\n",
      "0.6168831168831169\n",
      "[[70 30]\n",
      " [29 25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.70       100\n",
      "           1       0.45      0.46      0.46        54\n",
      "\n",
      "    accuracy                           0.62       154\n",
      "   macro avg       0.58      0.58      0.58       154\n",
      "weighted avg       0.62      0.62      0.62       154\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "[INFO] Performance on 3 fold\n",
      "0.6862745098039216\n",
      "[[77 23]\n",
      " [25 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       100\n",
      "           1       0.55      0.53      0.54        53\n",
      "\n",
      "    accuracy                           0.69       153\n",
      "   macro avg       0.65      0.65      0.65       153\n",
      "weighted avg       0.68      0.69      0.68       153\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "[INFO] Performance on 4 fold\n",
      "0.7124183006535948\n",
      "[[80 20]\n",
      " [24 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.78       100\n",
      "           1       0.59      0.55      0.57        53\n",
      "\n",
      "    accuracy                           0.71       153\n",
      "   macro avg       0.68      0.67      0.68       153\n",
      "weighted avg       0.71      0.71      0.71       153\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "All accuracy [0.6688311688311688, 0.6493506493506493, 0.6168831168831169, 0.6862745098039216, 0.7124183006535948]\n",
      "Max: 0.7124183006535948\n",
      "Average 0.6667515491044902\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors=2, p=3, weights='distance')\n",
    "\n",
    "accuracy = []\n",
    "print('[INFO] KNN Model Performance...\\n')\n",
    "i = 0\n",
    "for train_index, test_index in skf.split(features, label):\n",
    "    # data split\n",
    "    x_train_fold, x_test_fold = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = label.iloc[train_index], label.iloc[test_index]\n",
    "    \n",
    "    # model training and its accuracy\n",
    "    knn_model.fit(x_train_fold, y_train_fold)\n",
    "    accuracy.append(knn_model.score(x_test_fold, y_test_fold))\n",
    "    \n",
    "    print('[INFO] Performance on', i, 'fold')\n",
    "    # model performance report\n",
    "    y_pred = knn_model.predict(x_test_fold)\n",
    "    print(knn_model.score(x_test_fold, y_test_fold))\n",
    "    print(confusion_matrix(y_test_fold, y_pred))\n",
    "    print(classification_report(y_test_fold, y_pred))\n",
    "    print('--'*30, '\\n')\n",
    "    i += 1\n",
    "    \n",
    "print('All accuracy', accuracy)\n",
    "print('Max:', max(accuracy))\n",
    "print('Average', np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3d0a79dc-fa6e-416f-a72f-46d920be5aae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T04:57:45.209314Z",
     "iopub.status.busy": "2021-10-18T04:57:45.209314Z",
     "iopub.status.idle": "2021-10-18T04:57:45.515865Z",
     "shell.execute_reply": "2021-10-18T04:57:45.514868Z",
     "shell.execute_reply.started": "2021-10-18T04:57:45.209314Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Logistic Regression Model Performance...\n",
      "\n",
      "[INFO] Performance on 0 fold\n",
      "0.7337662337662337\n",
      "[[84 16]\n",
      " [25 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.84      0.80       100\n",
      "           1       0.64      0.54      0.59        54\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.69      0.69       154\n",
      "weighted avg       0.73      0.73      0.73       154\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "[INFO] Performance on 1 fold\n",
      "0.7727272727272727\n",
      "[[87 13]\n",
      " [22 32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       100\n",
      "           1       0.71      0.59      0.65        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.73      0.74       154\n",
      "weighted avg       0.77      0.77      0.77       154\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "[INFO] Performance on 2 fold\n",
      "0.7142857142857143\n",
      "[[83 17]\n",
      " [27 27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79       100\n",
      "           1       0.61      0.50      0.55        54\n",
      "\n",
      "    accuracy                           0.71       154\n",
      "   macro avg       0.68      0.67      0.67       154\n",
      "weighted avg       0.71      0.71      0.71       154\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "[INFO] Performance on 3 fold\n",
      "0.8235294117647058\n",
      "[[93  7]\n",
      " [20 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       100\n",
      "           1       0.82      0.62      0.71        53\n",
      "\n",
      "    accuracy                           0.82       153\n",
      "   macro avg       0.82      0.78      0.79       153\n",
      "weighted avg       0.82      0.82      0.82       153\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "[INFO] Performance on 4 fold\n",
      "0.7516339869281046\n",
      "[[84 16]\n",
      " [22 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82       100\n",
      "           1       0.66      0.58      0.62        53\n",
      "\n",
      "    accuracy                           0.75       153\n",
      "   macro avg       0.73      0.71      0.72       153\n",
      "weighted avg       0.75      0.75      0.75       153\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "All accuracy [0.7337662337662337, 0.7727272727272727, 0.7142857142857143, 0.8235294117647058, 0.7516339869281046]\n",
      "Max: 0.8235294117647058\n",
      "Average 0.7591885238944063\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "accuracy = []\n",
    "print('[INFO] Logistic Regression Model Performance...\\n')\n",
    "i = 0\n",
    "for train_index, test_index in skf.split(features, label):\n",
    "    # data split\n",
    "    x_train_fold, x_test_fold = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = label.iloc[train_index], label.iloc[test_index]\n",
    "    \n",
    "    # model training and its accuracy\n",
    "    lr_model.fit(x_train_fold, y_train_fold)\n",
    "    accuracy.append(lr_model.score(x_test_fold, y_test_fold))\n",
    "    \n",
    "    print('[INFO] Performance on', i, 'fold')\n",
    "    # model performance report\n",
    "    y_pred = lr_model.predict(x_test_fold)\n",
    "    print(lr_model.score(x_test_fold, y_test_fold))\n",
    "    print(confusion_matrix(y_test_fold, y_pred))\n",
    "    print(classification_report(y_test_fold, y_pred))\n",
    "    print('--'*30, '\\n')\n",
    "    i += 1\n",
    "    \n",
    "print('All accuracy', accuracy)\n",
    "print('Max:', max(accuracy))\n",
    "print('Average', np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "013450b9-fb44-4588-9fb4-f3fe3c3892e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T04:52:10.743984Z",
     "iopub.status.busy": "2021-10-18T04:52:10.742987Z",
     "iopub.status.idle": "2021-10-18T04:52:14.158960Z",
     "shell.execute_reply": "2021-10-18T04:52:14.156966Z",
     "shell.execute_reply.started": "2021-10-18T04:52:10.743984Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random Forest Model Performance...\n",
      "\n",
      "[INFO] Performance on 0 fold\n",
      "0.7077922077922078\n",
      "[[84 16]\n",
      " [29 25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.79       100\n",
      "           1       0.61      0.46      0.53        54\n",
      "\n",
      "    accuracy                           0.71       154\n",
      "   macro avg       0.68      0.65      0.66       154\n",
      "weighted avg       0.70      0.71      0.70       154\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "[INFO] Performance on 1 fold\n",
      "0.7857142857142857\n",
      "[[83 17]\n",
      " [16 38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83       100\n",
      "           1       0.69      0.70      0.70        54\n",
      "\n",
      "    accuracy                           0.79       154\n",
      "   macro avg       0.76      0.77      0.77       154\n",
      "weighted avg       0.79      0.79      0.79       154\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "[INFO] Performance on 2 fold\n",
      "0.7337662337662337\n",
      "[[85 15]\n",
      " [26 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81       100\n",
      "           1       0.65      0.52      0.58        54\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.68      0.69       154\n",
      "weighted avg       0.73      0.73      0.73       154\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "[INFO] Performance on 3 fold\n",
      "0.7908496732026143\n",
      "[[84 16]\n",
      " [16 37]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       100\n",
      "           1       0.70      0.70      0.70        53\n",
      "\n",
      "    accuracy                           0.79       153\n",
      "   macro avg       0.77      0.77      0.77       153\n",
      "weighted avg       0.79      0.79      0.79       153\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "[INFO] Performance on 4 fold\n",
      "0.7581699346405228\n",
      "[[81 19]\n",
      " [18 35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81       100\n",
      "           1       0.65      0.66      0.65        53\n",
      "\n",
      "    accuracy                           0.76       153\n",
      "   macro avg       0.73      0.74      0.73       153\n",
      "weighted avg       0.76      0.76      0.76       153\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "All accuracy [0.7077922077922078, 0.7857142857142857, 0.7337662337662337, 0.7908496732026143, 0.7581699346405228]\n",
      "Max: 0.7908496732026143\n",
      "Average 0.7552584670231728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, min_samples_leaf=2, n_jobs=-1, random_state=21)\n",
    "\n",
    "accuracy = []\n",
    "print('[INFO] Random Forest Model Performance...\\n')\n",
    "i = 0\n",
    "for train_index, test_index in skf.split(features, label):\n",
    "    # data split\n",
    "    x_train_fold, x_test_fold = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = label.iloc[train_index], label.iloc[test_index]\n",
    "    \n",
    "    # model training and its accuracy\n",
    "    rf_model.fit(x_train_fold, y_train_fold)\n",
    "    accuracy.append(rf_model.score(x_test_fold, y_test_fold))\n",
    "    \n",
    "    print('[INFO] Performance on', i, 'fold')\n",
    "    # model performance report\n",
    "    y_pred = rf_model.predict(x_test_fold)\n",
    "    print(rf_model.score(x_test_fold, y_test_fold))\n",
    "    print(confusion_matrix(y_test_fold, y_pred))\n",
    "    print(classification_report(y_test_fold, y_pred))\n",
    "    print('--'*30, '\\n')\n",
    "    i += 1\n",
    "    \n",
    "print('All accuracy', accuracy)\n",
    "print('Max:', max(accuracy))\n",
    "print('Average', np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3eae1551-2483-405b-8a8f-3dd2396fa63d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T04:46:54.426049Z",
     "iopub.status.busy": "2021-10-18T04:46:54.426049Z",
     "iopub.status.idle": "2021-10-18T04:46:56.244387Z",
     "shell.execute_reply": "2021-10-18T04:46:56.241395Z",
     "shell.execute_reply.started": "2021-10-18T04:46:54.426049Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] SVM Model Performance...\n",
      "\n",
      "[INFO] Performance on 0 fold\n",
      "0.7142857142857143\n",
      "[[82 18]\n",
      " [26 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79       100\n",
      "           1       0.61      0.52      0.56        54\n",
      "\n",
      "    accuracy                           0.71       154\n",
      "   macro avg       0.68      0.67      0.67       154\n",
      "weighted avg       0.71      0.71      0.71       154\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "[INFO] Performance on 1 fold\n",
      "0.7792207792207793\n",
      "[[87 13]\n",
      " [21 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       100\n",
      "           1       0.72      0.61      0.66        54\n",
      "\n",
      "    accuracy                           0.78       154\n",
      "   macro avg       0.76      0.74      0.75       154\n",
      "weighted avg       0.77      0.78      0.77       154\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "[INFO] Performance on 2 fold\n",
      "0.7337662337662337\n",
      "[[85 15]\n",
      " [26 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81       100\n",
      "           1       0.65      0.52      0.58        54\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.68      0.69       154\n",
      "weighted avg       0.73      0.73      0.73       154\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "[INFO] Performance on 3 fold\n",
      "0.8431372549019608\n",
      "[[93  7]\n",
      " [17 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89       100\n",
      "           1       0.84      0.68      0.75        53\n",
      "\n",
      "    accuracy                           0.84       153\n",
      "   macro avg       0.84      0.80      0.82       153\n",
      "weighted avg       0.84      0.84      0.84       153\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "[INFO] Performance on 4 fold\n",
      "0.7516339869281046\n",
      "[[84 16]\n",
      " [22 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82       100\n",
      "           1       0.66      0.58      0.62        53\n",
      "\n",
      "    accuracy                           0.75       153\n",
      "   macro avg       0.73      0.71      0.72       153\n",
      "weighted avg       0.75      0.75      0.75       153\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "All accuracy [0.7142857142857143, 0.7792207792207793, 0.7337662337662337, 0.8431372549019608, 0.7516339869281046]\n",
      "Max: 0.8431372549019608\n",
      "Average 0.7644087938205585\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(kernel='linear', degree=20, random_state=0)\n",
    "\n",
    "accuracy = []\n",
    "print('[INFO] SVM Model Performance...\\n')\n",
    "i = 0\n",
    "for train_index, test_index in skf.split(features, label):\n",
    "    # data split\n",
    "    x_train_fold, x_test_fold = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = label.iloc[train_index], label.iloc[test_index]\n",
    "    \n",
    "    # model training and its accuracy\n",
    "    svm_model.fit(x_train_fold, y_train_fold)\n",
    "    accuracy.append(svm_model.score(x_test_fold, y_test_fold))\n",
    "    \n",
    "    print('[INFO] Performance on', i, 'fold')\n",
    "    # model performance report\n",
    "    y_pred = svm_model.predict(x_test_fold)\n",
    "    print(svm_model.score(x_test_fold, y_test_fold))\n",
    "    print(confusion_matrix(y_test_fold, y_pred))\n",
    "    print(classification_report(y_test_fold, y_pred))\n",
    "    print('--'*30, '\\n')\n",
    "    i += 1\n",
    "    \n",
    "print('All accuracy', accuracy)\n",
    "print('Max:', max(accuracy))\n",
    "print('Average', np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a48a96a4-764d-4694-9651-93f1bea87bee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T04:47:01.276886Z",
     "iopub.status.busy": "2021-10-18T04:47:01.276886Z",
     "iopub.status.idle": "2021-10-18T04:47:05.218834Z",
     "shell.execute_reply": "2021-10-18T04:47:05.216839Z",
     "shell.execute_reply.started": "2021-10-18T04:47:01.276886Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] XGBoost Model Performance...\n",
      "\n",
      "[INFO] Performance on 0 fold\n",
      "0.7207792207792207\n",
      "[[81 19]\n",
      " [24 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79       100\n",
      "           1       0.61      0.56      0.58        54\n",
      "\n",
      "    accuracy                           0.72       154\n",
      "   macro avg       0.69      0.68      0.69       154\n",
      "weighted avg       0.72      0.72      0.72       154\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "[INFO] Performance on 1 fold\n",
      "0.8116883116883117\n",
      "[[82 18]\n",
      " [11 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85       100\n",
      "           1       0.70      0.80      0.75        54\n",
      "\n",
      "    accuracy                           0.81       154\n",
      "   macro avg       0.79      0.81      0.80       154\n",
      "weighted avg       0.82      0.81      0.81       154\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "[INFO] Performance on 2 fold\n",
      "0.7142857142857143\n",
      "[[82 18]\n",
      " [26 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79       100\n",
      "           1       0.61      0.52      0.56        54\n",
      "\n",
      "    accuracy                           0.71       154\n",
      "   macro avg       0.68      0.67      0.67       154\n",
      "weighted avg       0.71      0.71      0.71       154\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "[INFO] Performance on 3 fold\n",
      "0.7516339869281046\n",
      "[[77 23]\n",
      " [15 38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.80       100\n",
      "           1       0.62      0.72      0.67        53\n",
      "\n",
      "    accuracy                           0.75       153\n",
      "   macro avg       0.73      0.74      0.73       153\n",
      "weighted avg       0.76      0.75      0.76       153\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "[INFO] Performance on 4 fold\n",
      "0.7516339869281046\n",
      "[[79 21]\n",
      " [17 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81       100\n",
      "           1       0.63      0.68      0.65        53\n",
      "\n",
      "    accuracy                           0.75       153\n",
      "   macro avg       0.73      0.73      0.73       153\n",
      "weighted avg       0.76      0.75      0.75       153\n",
      "\n",
      "------------------------------------------------------------ \n",
      "\n",
      "All accuracy [0.7207792207792207, 0.8116883116883117, 0.7142857142857143, 0.7516339869281046, 0.7516339869281046]\n",
      "Max: 0.8116883116883117\n",
      "Average 0.7500042441218912\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb_model = XGBClassifier(n_estimators=200, random_state=0, eval_metric='mlogloss')\n",
    "\n",
    "accuracy = []\n",
    "print('[INFO] XGBoost Model Performance...\\n')\n",
    "i = 0\n",
    "for train_index, test_index in skf.split(features, label):\n",
    "    # data split\n",
    "    x_train_fold, x_test_fold = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = label.iloc[train_index], label.iloc[test_index]\n",
    "    \n",
    "    # model training and its accuracy\n",
    "    xgb_model.fit(x_train_fold, y_train_fold)\n",
    "    accuracy.append(xgb_model.score(x_test_fold, y_test_fold))\n",
    "    \n",
    "    print('[INFO] Performance on', i, 'fold')\n",
    "    # model performance report\n",
    "    y_pred = xgb_model.predict(x_test_fold)\n",
    "    print(xgb_model.score(x_test_fold, y_test_fold))\n",
    "    print(confusion_matrix(y_test_fold, y_pred))\n",
    "    print(classification_report(y_test_fold, y_pred))\n",
    "    print('--'*30, '\\n')\n",
    "    i += 1\n",
    "    \n",
    "print('All accuracy', accuracy)\n",
    "print('Max:', max(accuracy))\n",
    "print('Average', np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d525975-6b5e-4282-bf25-bad789864610",
   "metadata": {},
   "source": [
    "<span style=\"color: yellow;\">__*Insights*__</span>\n",
    "* `SVM` is the best performer out of all with highest accuracy of 84%\n",
    "* Out of all models we tried, only `Logistic Regression`, `Random Forest`, `SVM` and `XGBoost` are giving accuracy above 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "298f997f-2f1b-40b0-a543-c42c2924455f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T04:05:43.755716Z",
     "iopub.status.busy": "2021-10-18T04:05:43.754719Z",
     "iopub.status.idle": "2021-10-18T04:05:43.765690Z",
     "shell.execute_reply": "2021-10-18T04:05:43.764731Z",
     "shell.execute_reply.started": "2021-10-18T04:05:43.755716Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f058b1ee-e5a7-4c4c-9493-7a7a1578e6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
